{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "from copy import deepcopy\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import copy\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 assignment - kmeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, max_iter=100):\n",
    "    \"\"\" Performs k-means clustering\n",
    "\n",
    "    Input:\n",
    "    X: (d x n) data matrix with each datapoint in one column\n",
    "    k: number of clusters\n",
    "    max_iter: maximum number of iterations\n",
    "\n",
    "    Output:\n",
    "    mu: (d x k) matrix with each cluster center in one column\n",
    "    r: assignment vector\n",
    "    \"\"\"\n",
    "    # initailize k random centroids at data mean\n",
    "    X_mean = np.mean(X, axis = 0)\n",
    "    w_init = np.array([np.random.normal(X_mean[i],1,k) for i in range(len(X_mean))])\n",
    "    w_q = w_init\n",
    "    converged = False\n",
    "    iteration = 1\n",
    "    m_q = np.zeros(len(X))\n",
    "    m_q_old = deepcopy(m_q)\n",
    "    while (not converged) & (iteration <= max_iter):\n",
    "        # calculate distance to centroids\n",
    "        D = np.linalg.norm(X[None, :] - w_q.T[:,None], axis = 2)\n",
    "        # assign every data point to its nearest centroids\n",
    "        m_q = np.argmin(D, axis=0)\n",
    "        # assign random data point to not empty centroids\n",
    "        m_empty = [x for x in range(k) if x not in np.unique(m_q)]\n",
    "        for m in m_empty:\n",
    "            m_q[random.randint(0,len(X)-1)] = m\n",
    "        # calculate position of centroids as mean of assigned data\n",
    "        w_q.T[np.unique(m_q)] = [np.sum(X[m_q == j], axis = 0) / (np.sum(m_q == j)) for j in np.unique(m_q)]\n",
    "        \n",
    "        # calculate objective\n",
    "        loss = np.sum([np.sum((X[m_q == j, :] - w_q[:,j])**2) for j in np.unique(m_q)])\n",
    "        print('iteration-step: ' + str(iteration))\n",
    "        print('number of changes in assignment: ' + str(list(m_q == m_q_old).count(False)))\n",
    "        print('loss function value: ' + str(loss))\n",
    "        if (m_q == m_q_old).all():\n",
    "            converged = True\n",
    "            break\n",
    "        \n",
    "        m_q_old = deepcopy(m_q)\n",
    "        iteration+=1\n",
    "    return w_q.T, m_q, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "k=3\n",
    "X = np.array([[0., 1., 1., 10., 10.25, 11., 10., 10.25, 11.],\n",
    "                  [0., 0., 1.,  0.,   0.5,  0.,  5.,   5.5,  5.]]).T\n",
    "perfect_r = [1,0,1,2,2,1,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration-step: 1\n",
      "number of changes in assignment: 6\n",
      "loss function value: 2.7500000000000004\n",
      "iteration-step: 2\n",
      "number of changes in assignment: 0\n",
      "loss function value: 2.7500000000000004\n"
     ]
    }
   ],
   "source": [
    "mu, r, loss =  kmeans(X,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.41666667,  5.16666667],\n",
       "       [10.41666667,  0.16666667],\n",
       "       [ 0.66666667,  0.33333333]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8173342d0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[:,0], X[:,1], 'o')\n",
    "plt.plot (mu.T[0], mu.T[1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment 2 - k-means agglomerative clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_agglo(X, r):\n",
    "    \"\"\" Performs agglomerative clustering with k-means criterion\n",
    "\n",
    "    Input:\n",
    "    X: (d x n) data matrix with each datapoint in one column\n",
    "    r: assignment vector\n",
    "\n",
    "    Output:\n",
    "    R: (k-1) x n matrix that contains cluster memberships before each step\n",
    "    kmloss: vector with loss after each step\n",
    "    mergeidx: (k-1) x 2 matrix that contains merge idx for each step\n",
    "    \"\"\"\n",
    "   \n",
    "    def kmeans_crit(X, r):\n",
    "        \"\"\" Computes k-means criterion\n",
    "\n",
    "        Input: \n",
    "        X: (d x n) data matrix with each datapoint in one column\n",
    "        r: assignment vector\n",
    "\n",
    "        Output:\n",
    "        value: scalar for sum of euclidean distances to cluster centers\n",
    "        \"\"\"\n",
    "        # calculate init centroids\n",
    "        w_q = np.array([np.sum(X[r == j], axis = 0) / (np.sum(r == j)) for j in np.unique(r)])\n",
    "        # compute initial clustering cost\n",
    "        loss = np.sum([np.sum((X[r == j, :] - w_q.T[:,np.unique(r) == j].reshape(len(w_q.T)))**2) for j in np.unique(r)])\n",
    "        return loss\n",
    "    \n",
    "    # initialization\n",
    "    k = len(np.unique(r))\n",
    "    n, d = np.shape(X)\n",
    "    R = np.zeros((k-1,n))\n",
    "    kmloss = np.zeros((k,1)) \n",
    "    mergeidx = np.zeros((k-1,2))\n",
    "    \n",
    "    kmloss[0] = kmeans_crit(X,r) \n",
    "    \n",
    "    \n",
    "    for l in range(1,k):\n",
    "        R[l-1] = r\n",
    "        # calculate init centroids\n",
    "        w_q = np.array([np.sum(X[r == j], axis = 0) / (np.sum(r == j)) for j in np.unique(r)])\n",
    "        # calculate distance between centroids -> covariance matrix\n",
    "        D = np.linalg.norm(w_q[None, :] - w_q[:,None], axis = 2)\n",
    "        # sort covariance ascending order\n",
    "        pairs = list(zip(np.argsort(D,kind='mergesort', axis = None)//len(D), np.argsort(D,kind='mergesort', axis = None)%len(D))) # zeile / spalte\n",
    "        # determine centroid pair with smallest loss, Caveat first elements are 0 explain the diagonal of the cov-matrix\n",
    "        min_pair_idx = pairs[k-l+1]\n",
    "        # get names of merged clusters by r (clusters used before have the highest index plus 1 )\n",
    "        min_pair = np.unique(r)[np.array(min_pair_idx)]  \n",
    "        mergeidx[l-1] = min_pair\n",
    "        #if np.isin(mergeidx[l-1, 0], mergeidx[:l-1]):\n",
    "        #    mergeidx[l-1, 0] = k+l-1\n",
    "\n",
    "        # new cluster membership\n",
    "        r[np.isin(r, min_pair)] = k+l-1\n",
    "        # new kmloss\n",
    "        kmloss[l] = kmeans_crit(X,r)\n",
    "    return R, kmloss, mergeidx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, kmloss, mergeidx = kmeans_agglo(X,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment 3 - dendrogram plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agglo_dendro(kmloss, mergeidx):\n",
    "    \"\"\" Plots dendrogram for agglomerative clustering\n",
    "\n",
    "    Input:\n",
    "    kmloss: vector with loss after each step\n",
    "    mergeidx: (k-1) x 2 matrix that contains merge idx for each step\n",
    "    \"\"\"\n",
    "    fourth_column = 2*np.ones((len(mergeidx),1)) # necessary for dendogram function, sample count\n",
    "    Z = np.concatenate([mergeidx, kmloss[1:], fourth_column], axis = 1)\n",
    "    \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=8.,  # font size for the x axis labels\n",
    "    )\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for _ in range(10):\n",
    "#    mu, r, _ = kmeans(X, k=3)\n",
    "#    r = r.flatten()\n",
    "#    R, kmloss, mergeidx = kmeans_agglo(X, r)\n",
    "#    mergeidx = np.array(mergeidx, dtype=int)\n",
    "#    if set([int(r[3]), int(r[6])]) == set(mergeidx[0, :]):\n",
    "#        worked = True\n",
    "#        imp.agglo_dendro(kmloss, mergeidx)\n",
    "#        break\n",
    "#    if not worked:\n",
    "#        raise AssertionError('test_agglo: the first merge is not correct.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agglo fails due to updated cluster names, which is mandatory for the dendogram plot -> question for Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration-step: 1\n",
      "number of changes in assignment: 6\n",
      "loss function value: 2.75\n",
      "iteration-step: 2\n",
      "number of changes in assignment: 0\n",
      "loss function value: 2.75\n"
     ]
    }
   ],
   "source": [
    "worked1 = False\n",
    "worked2 = False\n",
    "for _ in range(10):\n",
    "    mu, r, _ = kmeans(X, k=3)\n",
    "    if (r[0]==r[1]==r[2]!=r[3] and r[3]==r[4]==r[5]!=r[6] and r[6]==r[7]==r[8]):\n",
    "        worked1 = True\n",
    "\n",
    "    # test one cluster center\n",
    "    if (np.linalg.norm(mu[0] - [10.41666, 0.1666]) < 0.1 or\n",
    "        np.linalg.norm(mu[1] - [10.41666, 0.1666]) < 0.1 or\n",
    "        np.linalg.norm(mu[2] - [10.41666, 0.1666]) < 0.1):\n",
    "            worked2 = True\n",
    "    if worked1 and worked2:\n",
    "        break\n",
    "if not worked1:\n",
    "    raise AssertionError('test_kmeans cluster assignments are wrong.')\n",
    "if not worked2:\n",
    "    raise AssertionError('test_kmeans did not find the correct cluster center.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment 4 - Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_pdf(X, mu, C):\n",
    "    \"\"\"\n",
    "    This function computes the probability density function when given a multivariate gaussian distribution as an input.\n",
    "    \n",
    "    Input:\n",
    "    X=data (nxd)\n",
    "    mu=centre of Gaussian distribution (1xd)\n",
    "    C=covariance matrix (nxn) , np.cov(X.T)\n",
    "    \n",
    "    Output:\n",
    "    y=probability density function (nx1)\n",
    "    \"\"\"\n",
    "\n",
    "    var=np.diagonal(C) #trace of cov matrix is var\n",
    "    \n",
    "    det=np.linalg.det(C)\n",
    "\n",
    "    #frac = 1 / (2**(X.shape[1]/2) * np.sqrt(var))  \n",
    "    \n",
    "    #frac = 1 / (((2*np.pi)**(X.shape[1]/2))*np.sqrt(det))\n",
    "    \n",
    "    frac = 1 / ((np.power((2*np.pi),(X.shape[1]/2)))*np.sqrt(det))\n",
    "    \n",
    "    exp = np.exp( (-1/2) *  (np.dot((np.square(X-mu)), 1/(var))) )\n",
    "    \n",
    "    #exp = np.exp( (-1/2) *  (np.dot((np.dot((X-mu).T,(X-mu))), 1/(var))) )\n",
    "    \n",
    "    #exp = np.exp( (-1/2) *  (np.dot(((X-mu)**2), 1/(var))) )\n",
    "    \n",
    "    #exp = np.exp(-((X-mu.reshape(1,mu.shape[0]))**2)/(2*var))\n",
    "\n",
    "    y = frac*exp\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignment 5 - Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_gmm(X, k, max_iter=100, init_kmeans=False, tol=0.00001):\n",
    "    \"\"\"\n",
    "    This function applies the EM algorithm for Gaussian Mixture Models. \n",
    "    \n",
    "    Inputs:\n",
    "    X = data (nxd)\n",
    "    k = number of gaussian components\n",
    "    max_iter = the maximum amount of iterations attempted to find convergence\n",
    "    init_kmeans = Initialises the EM algorithm using kmeans function, if True. Default is False.\n",
    "    tol = The tolerance set for the convergence condition\n",
    "    \n",
    "    Outputs:\n",
    "    pi = probability that a datapoint belongs to a cluster (1xk)\n",
    "    mu = center points of clusters (kxd)\n",
    "    sigma = list of k dxd covariance matrices\n",
    "    loglik = the loglikehlihood of each datapoint after convergence\n",
    "    \"\"\"\n",
    "    \n",
    "    if init_kmeans==True:\n",
    "        #1.a INIT_KMEANS\n",
    "        mu, r, _ = kmeans(X,k)\n",
    "        unique, counts = np.unique(r, return_counts=True)\n",
    "        pi = counts/np.sum(counts)\n",
    "        \n",
    "    else:\n",
    "        #1.b RANDOM INITIALISATIONS\n",
    "        pi = np.full(shape=(k,1), fill_value=1/k) #kx1\n",
    "        rand_samples = np.random.choice(X.shape[0], size=(k,), replace=False) #choose k random data points\n",
    "        mu = X[rand_samples] #centroid initialisation as random points, kxd\n",
    "    \n",
    "    \n",
    "    #setup storage and loop\n",
    "    sigma = [np.eye(X.shape[1]) for i in range(k)] #dxd\n",
    "    likelihoods = np.zeros(shape=(X.shape[0],k),dtype=float) #nxk\n",
    "    converged = False\n",
    "    iteration = 1\n",
    "    while (not converged) & (iteration <= max_iter):\n",
    "    \n",
    "        print('Iteration Number:\\n',iteration)\n",
    "    \n",
    "        #2. E-STEP - compute new likelihoods and responsibilities\n",
    "        old_likelihoods = copy.deepcopy(likelihoods)\n",
    "        #print('Old likelihoods\\n', old_likelihoods)\n",
    "        \n",
    "        #2.1 first find all k likelihoods\n",
    "        for i in range(k):\n",
    "            #nx1                             1x1 X nx1  = nx1 \n",
    "            likelihood = (pi[i] * norm_pdf(X,mu[i],sigma[i])) #norm_pdf written to handle mu=(1xd) only\n",
    "            likelihoods.T[i]=likelihood\n",
    "        print('New likelihoods\\n',likelihoods)\n",
    "    \n",
    "        #2.2 use likelihoods to calculate individual k responsibilities\n",
    "            #nxk            nxk              nx1\n",
    "        responsibilities = likelihoods / np.sum(likelihoods, axis=1).reshape(likelihoods.shape[0],1)\n",
    "    \n",
    "        #3. M-STEP - compute new n,pi,mu,sigma\n",
    "        #1xk\n",
    "        n = np.sum(responsibilities,axis=0)\n",
    "        #1xk\n",
    "        pi = n / np.sum(n,axis=0)\n",
    "        #kxd                    (nxkx0)x(nx0xd)=nxkxd --> kxd / kx1\n",
    "        mu = np.sum(responsibilities[:,:,None]*X[:,None,:],axis=0)/n.reshape(n.shape[0],1)\n",
    "        #kxdxd         =  sum ((nxkx0x0)     x    (nxkxdx0)x(nxkx0xd)) = nxkxdxd-->kxdxd/kx0x0\n",
    "        sigma = np.sum(responsibilities[:,:,None,None]*(X[:,None,:,None]-mu[None,:,:,None])*(X[:,None,None,:]-mu[None,:,None,:]),axis=0) / n[:,None,None]\n",
    "                                                    #   (nx0xdx0-nxkx0x0)-->(nxkxdx0)\n",
    "    \n",
    "        #break condition\n",
    "        if (old_likelihoods-likelihoods).all()<tol:\n",
    "            converged=True\n",
    "\n",
    "        iteration=iteration+1\n",
    "        \n",
    "    #return as a list of covariances    \n",
    "    list_sigma=[sigma[i,:,:] for i in range(k)]\n",
    "    return pi, mu, list_sigma, likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNMENT 6 GMM PLOT ---> NEEDS SCIPY.LINALG.SQRTM\n",
    "def plot_gmm_solution(X,mu,sigma):\n",
    "    \"\"\"\n",
    "    This function plots the different gaussians found by the EM algorithm as ellipses centred around the distributions' means.\n",
    "    \n",
    "    Input:\n",
    "    X=data (nxd)\n",
    "    mu=distribution centres (kxd)\n",
    "    sigma=list of k dxd covariance matrices\n",
    "    \n",
    "    \"\"\"\n",
    "    #plot data points and setup plot parameters\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.scatter(X.T[0],X.T[1],s=20)\n",
    "    plt.title('GMM solution found by EM algorithm')\n",
    "    plt.ylabel('X2')\n",
    "    plt.xlabel('X1')\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "    #draw ellipse\n",
    "    for i,sig in enumerate(sigma):\n",
    "        tline = np.linspace(0, 2 * np.pi, 100)\n",
    "        sphere = np.vstack((np.sin([tline]), np.cos([tline])))\n",
    "        ellipse = sp.linalg.sqrtm(sig).dot(sphere)\n",
    "        plt.plot(mu[i][0] + ellipse[0, :], mu[i][1] + ellipse[1, :],linewidth=4)\n",
    "        #plot centre points\n",
    "        plt.scatter(mu[i][0],mu[i][1],c='r',marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
