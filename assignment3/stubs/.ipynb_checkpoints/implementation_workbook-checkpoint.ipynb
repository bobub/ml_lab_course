{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class krr():\n",
    "    \"\"\"\n",
    "    Class used to apply kernel ridge regression.\n",
    "    \n",
    "    Inputs:\n",
    "    kernel = kernel to be used (linear, polynomial, gaussian)\n",
    "    kernelparameter = none, degree d, kernel width sigma (for linear, polynomial, gaussian respectively)\n",
    "    regularization = regularisation constant C (default is 0, which then uses leave one out cross validation LOOCV as defined)\n",
    "    \n",
    "    Methods:\n",
    "    fit: fits Xtrain and ytrain with the desired kernel\n",
    "    predict: makes predictions using fit on new Xtest data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='linear', kernelparameter=1, regularization=0):\n",
    "        #define K according to kernel specification\n",
    "        if kernel=='linear':\n",
    "            def K(x,x_):\n",
    "                self.k = np.dot(x,x_.T) # or np.inner()?\n",
    "                return self.k\n",
    "            \n",
    "        if kernel=='polynomial':\n",
    "            def K(x,x_):\n",
    "                self.k = (np.dot(x,x_.T)+1)**kernelparameter\n",
    "                return self.k\n",
    "                \n",
    "        if kernel=='gaussian':\n",
    "            def K(x,x_):\n",
    "                self.k = np.exp(-(np.linalg.norm(x-x_.T)**2)/(2*(kernelparameter)**2))\n",
    "                return self.k\n",
    "    \n",
    "            \n",
    "    def LOOCV(self,K_matrix,num=20,power=2):\n",
    "        \"\"\"\n",
    "        Executes leave one out cross validation for kernel ridge regression for automatic selection of C, the regularisation parameter.\n",
    "        Uses mean eigenvalue as centre of logarithmically spaced candidates for C. \n",
    "    \n",
    "        Inputs:\n",
    "        self = KRR instance\n",
    "        K_matrix = gram matrix\n",
    "        num = number of candidates for C\n",
    "        power = max power of logarithmic scale above/below mean eigenvalue.\n",
    "        \n",
    "        Output:\n",
    "        best_C = the best regularisation constant which gives the lowest cross validation error, epsilon\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        #create candidates\n",
    "        a = np.logspace(-power,power,num)\n",
    "        C = a*np.mean(eigval) #candidates denoted as c\n",
    "    \n",
    "        #use EVD's results for efficient computation\n",
    "        eigval, eigvec = np.linalg.eig(K_matrix)\n",
    "    \n",
    "        #compute S\n",
    "        #cxnxn\n",
    "        S = (np.dot(eigvec,np.diag(eigval))[None,:,:]*np.linalg.inv(np.diag(eigval) + C[:,None,None]*np.eye(K_matrix.shape[0])[None,:,:]))*eigvec.T[None,:,:]\n",
    "\n",
    "        #cxnx1 = cxnxn X nx1\n",
    "        Sy = np.dot(S,ytrain)\n",
    "        \n",
    "        #calculate all quadratic losses for c candidates\n",
    "        #c   =    0xnx1-cxnx1 / (1-cxn)\n",
    "        epsilon = np.sum((((ytrain[None,:,:]-Sy)/(1-np.diagonal(S,axis1=1,axis2=2))[:,:,None])**2),axis=1)\n",
    "    \n",
    "        best_epsilon = epsilon[np.argmin(epsilon)]\n",
    "    \n",
    "        best_C = C[np.argmin(epsilon)]\n",
    "    \n",
    "        return best_C\n",
    "            \n",
    "            \n",
    "    def fit(self, Xtrain, ytrain, kernel=False, kernelparameter=False, regularization=False):\n",
    "        #nxn \n",
    "        K_matrix = K(Xtrain,Xtrain)\n",
    "        #nx1 =                  (nxn)^-1            x         nx1            = nx1  \n",
    "        self.alpha = np.dot( np.inv(K_matrix + regularization*np.eye(Xtrain.shape[0])), ytrain) \n",
    "        \n",
    "    \n",
    "    def predict(self,Xtest):\n",
    "        #nx1 = nx1 X \n",
    "        y_pred = np.inner(self.alpha.T, K(Xtrain,Xtest).T)\n",
    "        return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class krr():\n",
    "    \"\"\"\n",
    "    Class used to apply kernel ridge regression.\n",
    "    \n",
    "    Inputs:\n",
    "    kernel = kernel to be used (linear, polynomial, gaussian)\n",
    "    kernelparameter = none, degree d, kernel width sigma (for linear, polynomial, gaussian respectively)\n",
    "    regularization = regularisation constant C (default is 0, which then uses leave one out cross validation LOOCV as defined)\n",
    "    \n",
    "    Methods:\n",
    "    fit: fits Xtrain and ytrain with the desired kernel\n",
    "    predict: makes predictions using fit on new Xtest data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='linear', kernelparameter=1, regularization=0, alpha=None, K_matrix=None):\n",
    "        self.kernel = kernel\n",
    "        self.alpha = alpha\n",
    "        self.kernelparameter = kernelparameter\n",
    "        self.regularization = regularization\n",
    "        self.K_matrix = K_matrix\n",
    "    \n",
    "    def K_linear(self,x,x_):\n",
    "        k = np.dot(x,x_.T) # or np.inner()?\n",
    "        return k\n",
    "            \n",
    "    def K_poly(self,x,x_):\n",
    "        k = (np.dot(x,x_.T)+1)**self.kernelparameter\n",
    "        return k\n",
    "\n",
    "    def K_gaussian(self,x,x_):\n",
    "        k = np.exp(-(np.linalg.norm(x-x_.T)**2)/(2*(self.kernelparameter)**2))\n",
    "        return k\n",
    "    \n",
    "    \n",
    "    def LOOCV(self,K_matrix,num=20,power=2):\n",
    "        \"\"\"\n",
    "        Executes leave one out cross validation for kernel ridge regression for automatic selection of C, the regularisation parameter.\n",
    "        Uses mean eigenvalue as centre of logarithmically spaced candidates for C. \n",
    "    \n",
    "        Inputs:\n",
    "        self = KRR instance\n",
    "        K_matrix = gram matrix\n",
    "        num = number of candidates for C\n",
    "        power = max power of logarithmic scale above/below mean eigenvalue.\n",
    "        \n",
    "        Output:\n",
    "        best_C = the best regularisation constant which gives the lowest cross validation error, epsilon\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #use EVD's results for efficient computation\n",
    "        eigval, eigvec = np.linalg.eig(K_matrix)\n",
    "    \n",
    "        #create candidates\n",
    "        a = np.logspace(-power,power,num)\n",
    "        C = a*np.mean(eigval) #candidates denoted as c\n",
    "    \n",
    "        #compute S\n",
    "        #cxnxn\n",
    "        S = (np.dot(eigvec,np.diag(eigval))[None,:,:]*np.linalg.inv(np.diag(eigval) + C[:,None,None]*np.eye(K_matrix.shape[0])[None,:,:]))*eigvec.T[None,:,:]\n",
    "\n",
    "        #cxnx1 = cxnxn X nx1\n",
    "        Sy = np.dot(S,ytrain)\n",
    "        \n",
    "        #calculate all quadratic losses for c candidates\n",
    "        #c   =    0xnx1-cxnx1 / (1-cxn)\n",
    "        epsilon = np.sum((((ytrain[None,:,:]-Sy)/(1-np.diagonal(S,axis1=1,axis2=2))[:,:,None])**2),axis=1)\n",
    "    \n",
    "        best_epsilon = epsilon[np.argmin(epsilon)]\n",
    "    \n",
    "        best_C = C[np.argmin(epsilon)]\n",
    "    \n",
    "        return best_C\n",
    "            \n",
    "            \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        \n",
    "        if self.kernel=='linear':   \n",
    "            self.K_matrix = K_linear(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.kernel=='polynomial':\n",
    "            self.K_matrix = K_poly(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.kernel=='gaussian':\n",
    "            self.K_matrix = K_gaussian(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.regularization==0:\n",
    "            self.regularization = LOOCV(K_matrix)\n",
    "        \n",
    "        #nx1 =                  (nxn)^-1            x         nx1            = nx1  \n",
    "        self.alpha = np.dot( np.inv(self.K_matrix + self.regularization*np.eye(Xtrain.shape[0])), ytrain) \n",
    "        \n",
    "    \n",
    "    def predict(self,Xtest):\n",
    "        #nx1 = nx1 X \n",
    "        if self.kernel=='linear':   \n",
    "        y_pred = np.inner(self.alpha.T, K_linear(Xtrain,Xtest).T)\n",
    "        \n",
    "        if self.kernel=='polynomial':\n",
    "        y_pred = np.inner(self.alpha.T, K_poly(Xtrain,Xtest).T)\n",
    "        \n",
    "        if self.kernel=='gaussian':\n",
    "        y_pred = np.inner(self.alpha.T, K_gaussian(Xtrain,Xtest).T)\n",
    "        \n",
    "        return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class krr():\n",
    "    \"\"\"\n",
    "    Class used to apply kernel ridge regression.\n",
    "    \n",
    "    Inputs:\n",
    "    kernel = kernel to be used (linear, polynomial, gaussian)\n",
    "    kernelparameter = none, degree d, kernel width sigma (for linear, polynomial, gaussian respectively)\n",
    "    regularization = regularisation constant C (default is 0, which then uses leave one out cross validation LOOCV as defined)\n",
    "    \n",
    "    Methods:\n",
    "    fit: fits Xtrain and ytrain with the desired kernel\n",
    "    predict: makes predictions using fit on new Xtest data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='linear', kernelparameter=1, regularization=0):\n",
    "        self.kernel=kernel\n",
    "        self.alpha = 0\n",
    "        self.kernelparameter=kernelparameter\n",
    "        self.regularization=regularization\n",
    "        self.K_matrix = 0\n",
    "        \n",
    "        if self.kernel=='linear':\n",
    "            def K(self,x,x_):\n",
    "                k = np.dot(x,x_.T) # or np.inner()?\n",
    "                return k\n",
    "            \n",
    "        if self.kernel=='polynomial':\n",
    "            def K(self,x,x_):\n",
    "                k = (np.dot(x,x_.T)+1)**self.kernelparameter\n",
    "                return k\n",
    "            \n",
    "        if self.kernel=='gaussian':\n",
    "            def K(self,x,x_):\n",
    "                k = np.exp(-(np.linalg.norm(x-x_.T)**2)/(2*(self.kernelparameter)**2))\n",
    "                return k\n",
    "    \n",
    "    def LOOCV(self,K_matrix,num=20,power=2):\n",
    "        \"\"\"\n",
    "        Executes leave one out cross validation for kernel ridge regression for automatic selection of C, the regularisation parameter.\n",
    "        Uses mean eigenvalue as centre of logarithmically spaced candidates for C. \n",
    "    \n",
    "        Inputs:\n",
    "        self = KRR instance\n",
    "        K_matrix = gram matrix\n",
    "        num = number of candidates for C\n",
    "        power = max power of logarithmic scale above/below mean eigenvalue.\n",
    "        \n",
    "        Output:\n",
    "        best_C = the best regularisation constant which gives the lowest cross validation error, epsilon\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #use EVD's results for efficient computation\n",
    "        eigval, eigvec = np.linalg.eig(K_matrix)\n",
    "    \n",
    "        #create candidates\n",
    "        a = np.logspace(-power,power,num)\n",
    "        C = a*np.mean(eigval) #candidates denoted as c\n",
    "    \n",
    "        #compute S\n",
    "        #cxnxn\n",
    "        S = (np.dot(eigvec,np.diag(eigval))[None,:,:]*np.linalg.inv(np.diag(eigval) + C[:,None,None]*np.eye(K_matrix.shape[0])[None,:,:]))*eigvec.T[None,:,:]\n",
    "\n",
    "        #cxnx1 = cxnxn X nx1\n",
    "        Sy = np.dot(S,ytrain)\n",
    "        \n",
    "        #calculate all quadratic losses for c candidates\n",
    "        #c   =    0xnx1-cxnx1 / (1-cxn)\n",
    "        epsilon = np.sum((((ytrain[None,:,:]-Sy)/(1-np.diagonal(S,axis1=1,axis2=2))[:,:,None])**2),axis=1)\n",
    "    \n",
    "        best_epsilon = epsilon[np.argmin(epsilon)]\n",
    "    \n",
    "        best_C = C[np.argmin(epsilon)]\n",
    "    \n",
    "        return best_C\n",
    "            \n",
    "            \n",
    "    def fit(self, Xtrain, ytrain):\n",
    "        \n",
    "        if self.kernel=='linear':   \n",
    "            self.K_matrix = K_linear(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.kernel=='polynomial':\n",
    "            self.K_matrix = K_poly(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.kernel=='gaussian':\n",
    "            self.K_matrix = K_gaussian(Xtrain,Xtrain)\n",
    "        \n",
    "        if self.regularization==0:\n",
    "            self.regularization = LOOCV(K_matrix)\n",
    "        \n",
    "        #nx1 =                  (nxn)^-1            x         nx1            = nx1  \n",
    "        self.alpha = np.dot( np.inv(self.K_matrix + self.regularization*np.eye(Xtrain.shape[0])), ytrain) \n",
    "        \n",
    "    \n",
    "    def predict(self,Xtest):\n",
    "        #nx1 = nx1 X \n",
    "        y_pred = np.inner(self.alpha.T, K(Xtrain,Xtest).T)\n",
    "        return y_pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dev and test cells\n",
    "\n",
    "Xtrain = np.array([[1,2,4],[1,4,1],[3,1,1],[2,4,1]])\n",
    "ytrain = np.array([[1],[0],[1],[1]])\n",
    "\n",
    "\n",
    "Xtest = np.array([[1,1,1],[1,2,1]])\n",
    "ytest = np.array([[1],[0]])\n",
    "\n",
    "regularization = 0.01\n",
    "kernelparameter =1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_gaussian(x,x_):\n",
    "    k = np.exp(-(np.linalg.norm(x-x_)**2)/(2*(kernelparameter)**2))\n",
    "    return k\n",
    "\n",
    "def K_linear(x,x_):\n",
    "    k = np.dot(x,x_.T) # or np.inner()?\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[21 13  9 14]\n",
      " [13 18  8 19]\n",
      " [ 9  8 11 11]\n",
      " [14 19 11 21]]\n",
      "42.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-b275cc47b1ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,4) "
     ]
    }
   ],
   "source": [
    "print(K_gaussian(Xtrain,Xtrain))\n",
    "\n",
    "print(K_linear(Xtrain,Xtrain))\n",
    "\n",
    "print(np.linalg.norm(Xtrain-ytrain)**2)\n",
    "\n",
    "print(Xtrain-Xtrain.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k [[21 13  9 14]\n",
      " [13 18  8 19]\n",
      " [ 9  8 11 11]\n",
      " [14 19 11 21]]\n",
      "(4, 4)\n",
      "(4, 1)\n",
      "k [[ 7  9]\n",
      " [ 6 10]\n",
      " [ 5  6]\n",
      " [ 7 11]]\n",
      "(4, 2)\n",
      "[[ 7  9]\n",
      " [ 6 10]\n",
      " [ 5  6]\n",
      " [ 7 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.46737969, 0.42013058]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manual computation - check against sklearn kernel ridge\n",
    "def K(x,x_):\n",
    "    k = np.dot(x,x_.T) # or np.inner()?\n",
    "    print('k',k)\n",
    "    return k\n",
    "\n",
    "#nxn \n",
    "K_matrix = K(Xtrain,Xtrain)\n",
    "print(K_matrix.shape)\n",
    "#nx1 =                  (nxn)^-1            x         nx1            = nx1  \n",
    "alpha = np.dot( np.linalg.inv(K_matrix + regularization*np.eye(Xtrain.shape[0])), ytrain) \n",
    "print(alpha.shape)\n",
    "\n",
    "result = K(Xtrain,Xtest)\n",
    "print(result.shape)\n",
    "print(result)\n",
    "y_pred = np.inner(alpha.T, result.T)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "clf = KernelRidge(alpha=0.01)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "y_pred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46737969],\n",
       "       [0.42013058]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.65882100e+01  8.77507404e+00  5.63671598e+00 -4.60294555e-16]\n"
     ]
    }
   ],
   "source": [
    "#results are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n",
      "(8, 1)\n",
      "(8, 8)\n",
      "[[1.31576127e+03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.64222764e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 6.41012075e+01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.04530059e+01\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.72192494e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.41487616e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.93752113e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 6.96349230e+00]]\n",
      "(20, 8, 8)\n",
      "[[[ 7.93138403e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  1.66768148e-01 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  1.97253336e-02 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  5.68299955e-03\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    2.29639917e-02  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  1.61747461e-01]]\n",
      "\n",
      " [[ 7.92376540e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  1.65506797e-01 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  1.93545161e-02 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  3.70468862e-03\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    1.98135997e-02  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  1.41776132e-01]]\n",
      "\n",
      " [[ 7.91142557e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  1.63498795e-01 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  1.87812111e-02 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  2.36682983e-03\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    1.62039544e-02  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  1.18098413e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.15879255e-02  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  3.52382240e-03 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  1.67930517e-04 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  1.75023893e-06\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    2.37352275e-05  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  1.88678785e-04]]\n",
      "\n",
      " [[ 7.56006073e-03  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  2.18768050e-03 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  1.03748592e-04 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  1.07789987e-06\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    1.46216231e-05  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  1.16237817e-04]]\n",
      "\n",
      " [[ 4.83252835e-03  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00  1.35401912e-03 -0.00000000e+00 ...  0.00000000e+00\n",
      "   -0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  6.40187622e-05 ... -0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 0.00000000e+00  0.00000000e+00 -0.00000000e+00 ...  6.63829667e-07\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 0.00000000e+00 -0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    9.00634183e-06  0.00000000e+00]\n",
      "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "    0.00000000e+00  7.16001546e-05]]]\n",
      "(20, 8)\n",
      "(20, 8, 1)\n",
      "(20, 1)\n",
      "[[5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]\n",
      " [5.]]\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "Xtrain = np.array([[1,2,4,1,5,7,1,6],[1,4,1,1,6,9,1,6],[3,7,7,4,3,2,1,1],[2,9,5,2,4,3,4,1],[1,2,3,4,5,6,7,8],[8,7,6,5,4,3,2,1],[6,5,4,3,8,9,7,2],[3,5,8,9,4,8,5,7]])\n",
    "ytrain = np.array([[1],[0],[1],[1],[0],[1],[0],[1]])\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "\n",
    "K_matrix = K_linear(Xtrain,Xtrain)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "eigval, eigvec = np.linalg.eig(K_matrix)\n",
    "print(eigvec.shape)\n",
    "# x      x    x x xxxCxxx x x    x       x     (log spaced candidates around mean eigval)\n",
    "print(np.diag(eigval))\n",
    "\n",
    "num = 20 #num of candidates for C ; denoted as c\n",
    "power = 2\n",
    "a = np.logspace(-power,power,num)\n",
    "C = a*np.mean(eigval)\n",
    "\n",
    "#cxnxn\n",
    "S = (np.dot(eigvec,np.diag(eigval))[None,:,:]*np.linalg.inv(np.diag(eigval) + C[:,None,None]*np.eye(K_matrix.shape[0])[None,:,:]))*eigvec.T[None,:,:]\n",
    "print(S.shape)\n",
    "print(S)\n",
    "print(np.diagonal(S,axis1=1,axis2=2).shape)\n",
    "\n",
    "#cxnx1 = cxnxn X nx1\n",
    "Sy = np.dot(S,ytrain)\n",
    "print(Sy.shape)\n",
    "\n",
    "\n",
    "#c   =    0xnx1-cxnx1 / (1-cxn)\n",
    "epsilon = np.sum((((ytrain[None,:,:]-Sy)/(1-np.diagonal(S,axis1=1,axis2=2))[:,:,None])**2),axis=1)\n",
    "\n",
    "print(epsilon.shape)\n",
    "\n",
    "print(epsilon)\n",
    "\n",
    "print(epsilon[np.argmin(epsilon)])\n",
    "\n",
    "\n",
    "#epsilon = \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(S)\n",
    "#def LOOCV(self,K_matrix):\n",
    "#    S = np.dot(K_matrix, (K_matrix + C))... #but C is 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x208078006a0>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "X_ax = np.linspace(-20,20,num=20)\n",
    "plt.plot(X_ax,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOOCV(self,K_matrix,num=20,power=2):\n",
    "    \"\"\"\n",
    "    Executes leave one out cross validation for kernel ridge regression for automatic selection of C, the regularisation parameter.\n",
    "    Uses mean eigenvalue as centre of logarithmically spaced candidates for C. \n",
    "    \n",
    "    Input:\n",
    "    self = KRR instance\n",
    "    K_matrix = gram matrix\n",
    "    num = number of candidates for C\n",
    "    power = max power of logarithmic scale above/below mean eigenvalue.\n",
    "    \"\"\"\n",
    "    \n",
    "    #create candidates\n",
    "    a = np.logspace(-power,power,num)\n",
    "    C = a*np.mean(eigval)\n",
    "    \n",
    "    #use EVD's results for efficient computation\n",
    "    eigval, eigvec = np.linalg.eig(K_matrix)\n",
    "    \n",
    "    #compute S\n",
    "    #cxnxn\n",
    "    S = (np.dot(eigvec,np.diag(eigval))[None,:,:]*np.linalg.inv(np.diag(eigval) + C[:,None,None]*np.eye(K_matrix.shape[0])[None,:,:]))*eigvec.T[None,:,:]\n",
    "\n",
    "    #cxnx1 = cxnxn X nx1\n",
    "    Sy = np.dot(S,ytrain)\n",
    "    \n",
    "    #c   =    0xnx1-cxnx1 / (1-cxn)\n",
    "    epsilon = np.sum((((ytrain[None,:,:]-Sy)/(1-np.diagonal(S,axis1=1,axis2=2))[:,:,None])**2),axis=1)\n",
    "    \n",
    "    best_epsilon = epsilon[np.argmin(epsilon)]\n",
    "    \n",
    "    best_C = C[np.argmin(epsilon)]\n",
    "    \n",
    "    return best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "krr = krr()\n",
    "krr.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
